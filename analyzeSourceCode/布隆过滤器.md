# 布隆过滤器

## 介绍

> **布隆过滤器**（英语：Bloom Filter）是1970年由布隆提出的。它实际上是一个很长的二进制向量和一系列随机映射函数。布隆过滤器可以用于**检索一个元素是否在一个集合中**。它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除困难。

可见，它解决的核心问题是 **检索一个元素是否在一个集合中**。原理大致如下：

当一个元素被加入集合时，通过 K 个散列函数将这个元素映射成一个二进制数组中的 K 个位置，把这些位置的值设置为 1。检索时，我们只要观察这些对应的位置的值是不是都是 1 就（大约）知道集合中有没有检索的元素：如果这 K 个位置中有任何一个 0，则被检索元素一定不在集合中；如果都是 1，则被检元素很可能在。这就是布隆过滤器的基本思想。有个[在线网站](https://llimllib.github.io/bloomfilter-tutorial/zh_CN/)可以玩耍。

<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/a/ac/Bloom_filter.svg/360px-Bloom_filter.svg.png" alt="img" style="zoom:150%;" />

## 以太坊如何使用布隆过滤器

事件是以太坊给外部应用程序发送消息的重要方式，应用为了获取自己需要的信息，需要在许多事件中快速的检索。虽然把数据都写入存储，依靠存储中的哈希索引，可以快速检索，但是以太坊的存储空间的计算代价很高，不可能用来存储大量的交易日志、事件等重复性很高的信息。布隆过滤器就是用来解决快速检索的问题。

当生成区块时，布隆过滤器中包含触发事件的合约的地址、事件中的 `indexed` 的字段。然后，布隆过滤器会包含在区块头中，同时实际日志和事件的数据不包含在区块中，只保留了日志和事件的检索方式。

外部的应用程序监听事件时，可以快速扫描区块头中的布隆过滤器，找到特定合约地址和其中的 `indexed` 字段，查找满足条件的事件。

## 源码的实现与原理

### `core/types/bloom9.go`

#### 布隆过滤器的定义

```go
const (
	// BloomByteLength represents the number of bytes used in a header log bloom.
	BloomByteLength = 256

	// BloomBitLength represents the number of bits used in a header log bloom.
	BloomBitLength = 8 * BloomByteLength //2048 位
)

// Bloom represents a 2048 bit bloom filter.
type Bloom [BloomByteLength]byte
```

可见，2048 位作为一个区块头的布隆过滤器。

#### 添加元素

字节数组转换成布隆过滤器，从末尾开始数，替换布隆过滤器的 d 个字节。

```go
// BytesToBloom converts a byte slice to a bloom filter.
// It panics if b is not of suitable size.
func BytesToBloom(b []byte) Bloom {
	var bloom Bloom
	bloom.SetBytes(b)
	return bloom
}
// SetBytes sets the content of b to the given bytes.
// It panics if d is not of suitable size.
func (b *Bloom) SetBytes(d []byte) {
	if len(b) < len(d) {
		panic(fmt.Sprintf("bloom bytes too big %d %d", len(b), len(d)))
	}
	copy(b[BloomByteLength-len(d):], d)
}
```

实际上，除了上面提到的替代字节的方法，也有真的类似于 `append` 的方法，叫做 `Add`，它实际上是选择 2048 位中的三个位置，将他的值值为 1。

```go
// Add adds d to the filter. Future calls of Test(d) will return true.
func (b *Bloom) Add(d []byte) {
	b.add(d, make([]byte, 6))
}

// add is internal version of Add, which takes a scratch buffer for reuse (needs to be at least 6 bytes)
func (b *Bloom) add(d []byte, buf []byte) {
	i1, v1, i2, v2, i3, v3 := bloomValues(d, buf)
	b[i1] |= v1
	b[i2] |= v2
	b[i3] |= v3
}

```

上面出现了比较重要的函数 `bloomValues`，他会选出 3 个字节，设置它们的值。

首先，选取索引为 1，3，5 的位置的字节，然后与0000 0111相与。假如索引为 1 的字节为 10110101，那么 1011 0101 & 0000 0111=0000 0101 也就是选择后三位的值。然后将 1 移 5位，也即为 0010 0000。这样就将某个字节的 8 位中的某一位设置成 1。

接着来选择这个字节所在的位置，将哈希值的末尾和 0111 1111 1111 相与，然后按照大端的方式，将这末尾的 16 位 转换成 uint16 的值，接着向做左移动 3 位，这样 最大为FF=255，这样恰好在布隆过滤器的长度范围内。

这样，通过字节内的移位和选择字节的位置，我们就巧妙地伪随机地将 2048 位中的三个 bit 设置为 1。

```go
// bloomValues returns the bytes (index-value pairs) to set for the given data
func bloomValues(data []byte, hashbuf []byte) (uint, byte, uint, byte, uint, byte) {
	sha := hasherPool.Get().(crypto.KeccakState) //选择 keccak-256 的哈希算法
	//哈希函数的用法，重置缓冲区、写入需要哈希的数据、读取需要哈希的数据
	sha.Reset()
	sha.Write(data)
	sha.Read(hashbuf)
	hasherPool.Put(sha)
	// The actual bits to flip
	//选取索引为 1，3，5 的位置的字节，然后与0000 0111相与。
	//假如索引为 1 的字节为 10110101，那么 1011 0101 & 0000 0111=0000 0101 也就是选择后三位的值。
	//然后将 1 移 5位，也即为 0010 0000
	v1 := byte(1 << (hashbuf[1] & 0x7))
	v2 := byte(1 << (hashbuf[3] & 0x7))
	v3 := byte(1 << (hashbuf[5] & 0x7))
	// The indices for the bytes to OR in
	//将哈希值的末尾和 0111 1111 1111 相与，然后按照大端的方式，将这末尾的 16 位 转换成 uint16 的值，
	//接着向做左移动 3 位，这样 最大为FF=255，这样恰好在布隆过滤器的长度范围内。
	i1 := BloomByteLength - uint((binary.BigEndian.Uint16(hashbuf)&0x7ff)>>3) - 1
	i2 := BloomByteLength - uint((binary.BigEndian.Uint16(hashbuf[2:])&0x7ff)>>3) - 1
	i3 := BloomByteLength - uint((binary.BigEndian.Uint16(hashbuf[4:])&0x7ff)>>3) - 1

	return i1, v1, i2, v2, i3, v3
}
```

#### 检查元素

源码中设置了检查某个元素是否在布隆过滤器中的方法，简单的比较是否对应的字节内的序列相同。

```go
// Test checks if the given topic is present in the bloom filter
func (b Bloom) Test(topic []byte) bool {
	i1, v1, i2, v2, i3, v3 := bloomValues(topic, make([]byte, 6))
	return v1 == v1&b[i1] &&
		v2 == v2&b[i2] &&
		v3 == v3&b[i3]
}
```

#### 设置布隆过滤器

可以看出来，布隆过滤器以相同的方式，记录触发日志的合约的地址和日志数据。

```go
// CreateBloom creates a bloom filter out of the give Receipts (+Logs)
func CreateBloom(receipts Receipts) Bloom {
	buf := make([]byte, 6) //因为哈希后的数据只需要前面 6 个字节
	var bin Bloom
	for _, receipt := range receipts {
		for _, log := range receipt.Logs {
			bin.add(log.Address.Bytes(), buf) //添加日志地址
			for _, b := range log.Topics {
				bin.add(b[:], buf) //添加日志
			}
		}
	}
	return bin
}
// LogsBloom returns the bloom bytes for the given logs
func LogsBloom(logs []*Log) []byte {
	buf := make([]byte, 6)
	var bin Bloom
	for _, log := range logs {
		bin.add(log.Address.Bytes(), buf)
		for _, b := range log.Topics {
			bin.add(b[:], buf)
		}
	}
	return bin[:]
}
```

### `core/bloombits/generator.go`

geth 中布隆过滤器的实现分成了三个文件， generator 生成布隆过滤器，matcher 用来匹配查询操作，scheduler 用于调度对单个 bit 值检索进行。



### `core/bloom bits/sheduler.go`

sheduler 主要是用于调度检索任务，是检索任务的调度器，也可以删除重复数据、缓存结果，降低 IO 消耗。

#### 数据结构定义

以太坊的布隆过滤器总共有 2048 位，以太坊会把若干个区块分成段，段作为检索的基本单位，4096 个区块为一段。checkpoint 和 时间检索也是这样。下面是一个检索请求，表示在特定的一段 section 中匹配 2048 位的过滤器中的哪一位。

```go
// request represents a bloom retrieval task to prioritize and pull from the local
// database or remotely from the network.
type request struct {
	section uint64 // Section index to retrieve the a bit-vector from
	bit     uint   // Bit index within the section to retrieve the vector of
}
```

response 和上面的 request 对应，注意**一段对应一个 response，检索任务以段(section) 为最小单位，而不是区块高度**，表示被检索的 bit 向量的状态（即请求的状态）。cached 缓存检索结果，用于去重。done 表示请求是否完成。

```go
// response represents the state of a requested bit-vector through a scheduler.
type response struct {
   cached []byte        // Cached bits to dedup multiple requests
   done   chan struct{} // Channel to allow waiting for completion
}
```

调度器的定义如下：scheduler 是查询某一段区块的布隆过滤器的 bit 向量中某一位的任务调度器。bit 表示查询 2048 位中哪一位；response 表示这个某个请求结构，一般而言会包含所在的一段，有 4096 个 请求结果 的键值对。在调度的同时，scheduler 会实现去重和缓存结果的功能。

```go
// scheduler handles the scheduling of bloom-filter retrieval operations for
// entire section-batches belonging to a single bloom bit. Beside scheduling the
// retrieval operations, this struct also deduplicates the requests and caches
// the results to minimize network/database overhead even in complex filtering
// scenarios.
type scheduler struct {
   bit       uint                 // Index of the bit in the bloom filter this scheduler is responsible for
   responses map[uint64]*response // Currently pending retrieval requests or already cached responses
   lock      sync.Mutex           // Lock protecting the responses from concurrent access
}
```

#### 执行调度任务

接下来看如何执行调度操作，这需要了解 Golang 的并发。 `run` 函数开始执行流水线式的调度任务，并且会返回结果。

- `sections chan uint64` 表示调度任务属于哪一段。
- `dist chan *request` 表示调度的输入，输入可以是本地的检索请求，可以是来自网络的检索请求。
- `done chan []byte` 表示输出的结果，用字节数组表示。
- ` quit chan struct{}` 是空结构体，通过阻塞控制，表示调度任务是否完成。

```go
// run creates a retrieval pipeline, receiving section indexes from sections and
// returning the results in the same order through the done channel. Concurrent
// runs of the same scheduler are allowed, leading to retrieval task deduplication.
func (s *scheduler) run(sections chan uint64, dist chan *request, done chan []byte, quit chan struct{}, wg *sync.WaitGroup) {
   //请求和回应之间的缓冲通道，用于阻塞和控制。

   // Create a forwarder channel between requests and responses of the same size as
   // the distribution channel (since that will block the pipeline anyway).
   pend := make(chan uint64, cap(dist))

   // Start the pipeline schedulers to forward between user -> distributor -> user
   wg.Add(2)
   go s.scheduleRequests(sections, dist, pend, quit, wg)
   go s.scheduleDeliveries(pend, done, quit, wg)
}
```

首先 `pend` 变量是用作阻塞控制的中间变量，它可以控制 `request` 和 `response` 的协调调度。这里再次强调，调度器可以接受外部的请求，会并发地同时处理网络地检索请求和用户自身的检索请求。

`scheduleRequests` 方法主要是将调度器检索的段 `reqs chan uint64` ，封装到 `dist chan *request `，然后初始化 `response`。`pend` 将会接收 `reqs chan uint64` 的值。

```go
// scheduleRequests reads section retrieval requests from the input channel,
// deduplicates the stream and pushes unique retrieval tasks into the distribution
// channel for a database or network layer to honour.
func (s *scheduler) scheduleRequests(reqs chan uint64, dist chan *request, pend chan uint64, quit chan struct{}, wg *sync.WaitGroup) {
	// Clean up the goroutine and pipeline when done
	defer wg.Done()
	defer close(pend)

	// Keep reading and scheduling section requests
	//一直将 section 封装到 requests，直到收到 quit 信号
	for {
		select {
		case <-quit: //收到退出信号就返回
			return
		case section, ok := <-reqs:
			//如果没有收到退出信号，继续初始化 responses，
			//将封装了段高度的请求传入 dist，再把 段高度传入 pend

			// New section retrieval requested
			if !ok {
				return
			}
			// Deduplicate retrieval requests
			unique := false //因为并发执行时可能一已经进入了协程，这里用于去重

			//阻塞其他协程，直到这一部分完成，Unlock
			s.lock.Lock()
			//如果请求为空，那么设置为已完成，避免重复执行
			if s.responses[section] == nil {
				s.responses[section] = &response{
					done: make(chan struct{}),
				}
				unique = true
			}
			s.lock.Unlock()

			// Schedule the section for retrieval and notify the deliverer to expect this section
			if unique {
				//如果对应的请求为空，但是还没有在其他协程结束，那么把结果分发出去
				select {
				case <-quit:
					return
				case dist <- &request{bit: s.bit, section: section}:
				}
			}
			//如果还没有结束，那么给 pend 赋值，pend 进入阻塞状态。
			select {
			case <-quit:
				return
			case pend <- section:
			}
		}
	}
}
```

接着，`scheduleDeliveries` 方法接收表示段高度的 `pend`，然后被 `response[section].done` 阻塞，直到外部调用 `deliver` 方法。

```go
// scheduleDeliveries reads section acceptance notifications and waits for them
// to be delivered, pushing them into the output data buffer.
func (s *scheduler) scheduleDeliveries(pend chan uint64, done chan []byte, quit chan struct{}, wg *sync.WaitGroup) {
	// Clean up the goroutine and pipeline when done
	defer wg.Done()
	defer close(done)

	// Keep reading notifications and scheduling deliveries
	for {
		select {
		case <-quit:
			return
		//结束 pend 的阻塞
		case idx, ok := <-pend:
			//如果没有收到退出信号，那么将每段的缓存写入 res，并且标注这一段的检索已经完成，
			//接着将缓存传递给 done，done 会被阻塞，直到后面的 deliver 执行。

			// New section retrieval pending
			if !ok {
				return
			}
			// Wait until the request is honoured
			s.lock.Lock()
			res := s.responses[idx] //写入 response，非常关键的一步。
			s.lock.Unlock()

			select {
			case <-quit:
				return
			case <-res.done: //这个为了阻塞，指代外部传入值才能解除阻塞
			}
			// Deliver the result
			select {
			case <-quit:
				return
			case done <- res.cached: //如果没有结束，将缓存的写入 done
			}
		}
	}
}
```

#### 核心逻辑

最后的 `deliver` 函数的参数 `data` 可以看作是 `[sections][]byte`，用二维数组表示这次调度的每一段对应的结果。当外部的匹配器完成了工作，就会传入 `data`，给每一段的 `response` 的结果赋值，也就是给 `cached` 赋值。这样解除了 `scheduleDeliveries` 的阻塞，将结果顺利的赋值给 `done`，执行调度任务的 `run` 方法也可以顺利的将结果从 `done chan []byte` 传出

```go
// deliver is called by the request distributor when a reply to a request arrives.
func (s *scheduler) deliver(sections []uint64, data [][]byte) {
	s.lock.Lock()
	defer s.lock.Unlock()

	for i, section := range sections {
		if res := s.responses[section]; res != nil && res.cached == nil { // Avoid non-requests and double deliveries
			res.cached = data[i]
			close(res.done)
		}
	}
}
```



### `core/bloombits/matcher.go`





## 参考

- [How does Ethereum make use of bloom filters?](https://ethereum.stackexchange.com/questions/3418/how-does-ethereum-make-use-of-bloom-filters)
- [维基百科：布隆过滤器](https://zh.wikipedia.org/wiki/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8)
- [core-bloombits源码分析](https://gitcode.net/mirrors/Billy1900/Ethereum-tutorial/-/blob/master/core-bloombits%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90.md)
-  [core, eth 模块-链的索引，搜索](https://knarfeh.com/2018/03/10/go-ethereum%20%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0%EF%BC%88core,%20eth%20%E6%A8%A1%E5%9D%97-%E9%93%BE%E7%9A%84%E7%B4%A2%E5%BC%95%EF%BC%8C%E6%90%9C%E7%B4%A2%EF%BC%89/)